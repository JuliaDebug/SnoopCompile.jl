<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Profile-guided despecialization · SnoopCompile</title><meta name="title" content="Profile-guided despecialization · SnoopCompile"/><meta property="og:title" content="Profile-guided despecialization · SnoopCompile"/><meta property="twitter:title" content="Profile-guided despecialization · SnoopCompile"/><meta name="description" content="Documentation for SnoopCompile."/><meta property="og:description" content="Documentation for SnoopCompile."/><meta property="twitter:description" content="Documentation for SnoopCompile."/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../">SnoopCompile</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">SnoopCompile.jl</a></li><li><span class="tocitem">Basic tutorials</span><ul><li><a class="tocitem" href="../invalidations/">Tutorial on <code>@snoop_invalidations</code></a></li><li><a class="tocitem" href="../snoop_inference/">Tutorial on <code>@snoop_inference</code></a></li><li><a class="tocitem" href="../snoop_llvm/">Tutorial on <code>@snoop_llvm</code></a></li><li class="is-active"><a class="tocitem" href>Profile-guided despecialization</a><ul class="internal"><li><a class="tocitem" href="#Using-the-PGDS-graphical-user-interface"><span>Using the PGDS graphical user interface</span></a></li></ul></li><li><a class="tocitem" href="../jet/">Tutorial on JET integration</a></li></ul></li><li><span class="tocitem">Advanced tutorials</span><ul><li><a class="tocitem" href="../snoop_inference_analysis/">Using <code>@snoop_inference</code> results to improve inferrability</a></li><li><a class="tocitem" href="../snoop_inference_parcel/">Using <code>@snoop_inference</code> to emit manual precompile directives</a></li></ul></li><li><span class="tocitem">Explanations</span><ul><li><a class="tocitem" href="../../explanations/tools/">Package roles and alternatives</a></li><li><a class="tocitem" href="../../explanations/gotchas/">Precompilation &quot;gotcha&quot;s</a></li><li><a class="tocitem" href="../../explanations/fixing_inference/">Techniques for fixing inference problems</a></li></ul></li><li><a class="tocitem" href="../../reference/">Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Basic tutorials</a></li><li class="is-active"><a href>Profile-guided despecialization</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Profile-guided despecialization</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/timholy/SnoopCompile.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/timholy/SnoopCompile.jl/blob/master/docs/src/tutorials/pgdsgui.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="pgds"><a class="docs-heading-anchor" href="#pgds">Profile-guided despecialization</a><a id="pgds-1"></a><a class="docs-heading-anchor-permalink" href="#pgds" title="Permalink"></a></h1><p>Julia&#39;s multiple dispatch allows developers to create methods for specific argument types. On top of this, the Julia compiler performs <em>automatic specialization</em>:</p><pre><code class="nohighlight hljs">function countnonzeros(A::AbstractArray)
    ...
end</code></pre><p>will be compiled separately for <code>Vector{Int}</code>, <code>Matrix{Float64}</code>, <code>SubArray{...}</code>, and so on, if it gets called for each of these types. Each specialization (each <code>MethodInstance</code> with different argument types) costs extra inference and code-generation time, so while specialization often improves runtime performance, that has to be weighed against the cost in latency. There are also cases in which <a href="https://docs.julialang.org/en/v1/manual/performance-tips/#The-dangers-of-abusing-multiple-dispatch-(aka,-more-on-types-with-values-as-parameters)">overspecialization can hurt both run-time and compile-time performance</a>. Consequently, an analysis of specialization can be a powerful tool for improving package quality.</p><p><code>SnoopCompile</code> ships with an interactive tool, <a href="../../reference/#SnoopCompile.pgdsgui"><code>pgdsgui</code></a>, short for &quot;Profile-guided despecialization.&quot; The name is a reference to a related technique, <a href="https://en.wikipedia.org/wiki/Profile-guided_optimization">profile-guided optimization</a> (PGO). Both PGO and PGDS use runtime profiling to help guide decisions about code optimization. PGO is often used in languages whose default mode is to avoid specialization, whereas PGDS seems more appropriate for a language like Julia which specializes by default. While PGO is sometimes an automatic part of the compiler that optimizes code midstream during execution, SnoopCompile&#39;s PGDS is a tool for making static changes (edits) to code. Again, this seems appropriate for a language where specialization typically happens prior to the first execution of the code.</p><h3 id="Add-SnoopCompileCore,-SnoopCompile,-and-helper-packages-to-your-environment"><a class="docs-heading-anchor" href="#Add-SnoopCompileCore,-SnoopCompile,-and-helper-packages-to-your-environment">Add SnoopCompileCore, SnoopCompile, and helper packages to your environment</a><a id="Add-SnoopCompileCore,-SnoopCompile,-and-helper-packages-to-your-environment-1"></a><a class="docs-heading-anchor-permalink" href="#Add-SnoopCompileCore,-SnoopCompile,-and-helper-packages-to-your-environment" title="Permalink"></a></h3><p>We&#39;ll add these packages to your <a href="https://pkgdocs.julialang.org/v1/environments/">default environment</a> so you can use them while in the package environment:</p><pre><code class="language-julia hljs">using Pkg
Pkg.add([&quot;SnoopCompileCore&quot;, &quot;SnoopCompile&quot;, &quot;PyPlot&quot;]);</code></pre><p>PyPLot is used for the PGDS interface in part to reduce interference with native-Julia plotting packages like Makie–it&#39;s a little awkward to depend on a package that you might be simultaneously modifying!</p><h2 id="Using-the-PGDS-graphical-user-interface"><a class="docs-heading-anchor" href="#Using-the-PGDS-graphical-user-interface">Using the PGDS graphical user interface</a><a id="Using-the-PGDS-graphical-user-interface-1"></a><a class="docs-heading-anchor-permalink" href="#Using-the-PGDS-graphical-user-interface" title="Permalink"></a></h2><p>To illustrate the use of PGDS, we&#39;ll examine an example in which some methods get specialized for hundreds of types. To keep this example short, we&#39;ll create functions that operate on types themselves.</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>As background to this example, for a <code>DataType</code> <code>T</code>, <code>T.name</code> returns a <code>Core.TypeName</code>, and <code>T.name.name</code> returns the name as a <code>Symbol</code>. <code>Base.unwrap_unionall(T)</code> preserves <code>DataType</code>s as-is, but converts a <code>UnionAll</code> type into a <code>DataType</code>.</p></div></div><pre><code class="language-julia hljs">&quot;&quot;&quot;
    spelltype(T::Type)

Spell out a type&#39;s name, one character at a time.
&quot;&quot;&quot;
function spelltype(::Type{T}) where T
    name = Base.unwrap_unionall(T).name.name
    str = &quot;&quot;
    for c in string(name)
        str *= c
    end
    return str
end

&quot;&quot;&quot;
    mappushes!(f, dest, src)

Like `map!` except it grows `dest` by one for each element in `src`.
&quot;&quot;&quot;
function mappushes!(f, dest, src)
    for item in src
        push!(dest, f(item))
    end
    return dest
end

mappushes(f, src) = mappushes!(f, [], src)</code></pre><p>There are two stages to PGDS: first (and preferrably starting in a fresh Julia session), we profile type-inference:</p><pre><code class="language-julia hljs">julia&gt; using SnoopCompileCore

julia&gt; Ts = subtypes(Any);  # get a long list of different types

julia&gt; tinf = @snoop_inference mappushes(spelltype, Ts);</code></pre><p>Then, <em>in the same session</em>, profile the runtime:</p><pre><code class="language-julia hljs">julia&gt; using Profile

julia&gt; @profile mappushes(spelltype, Ts);</code></pre><p>Typically, it&#39;s best if the workload here is reflective of a &quot;real&quot; workload (test suites often are not), so that you get a realistic view of where your code spends its time during actual use.</p><p>Now let&#39;s launch the PDGS GUI:</p><pre><code class="language-julia hljs">julia&gt; using SnoopCompile

julia&gt; import PyPlot        # the GUI is dependent on PyPlot, must load it before the next line

julia&gt; mref, ax = pgdsgui(tinf);</code></pre><p>You should see something like this:</p><p><img src="../../assets/pgds_spec.png" alt="pgdsgui"/></p><p>In this graph, each dot corresponds to a single method; for this method, we plot inference time (vertical axis) against the run time (horizontal axis). The coloration of each dot encodes the number of specializations (the number of distinct <code>MethodInstance</code>s) for that method; by default it even includes the number of times the method was inferred for specific constants (<a href="https://en.wikipedia.org/wiki/Constant_folding">constant propagation</a>), although you can exclude those cases using the <code>consts=false</code> keyword. Finally, the edge of each dot encodes the fraction of time spent on runtime dispatch (aka, type-instability), with black indicating 0% and bright red indicating 100%.</p><p>In this plot, we can see that no method runs for more than 0.01 seconds, whereas some methods have an aggregate inference time of up to 1s. Overall, inference-time dominates this plot. Moreover, for the most expensive cases, the number of specializations is in the hundreds or thousands.</p><p>To learn more about <em>what</em> is being specialized, just click on one of the dots; if you choose the upper-left dot (the one with highest inference time), you should see something like this in your REPL:</p><pre><code class="language-julia hljs">spelltype(::Type{T}) where T in Main at REPL[1]:6 (586 specializations)</code></pre><p>This tells you the method corresponding to this dot. Moreover, <code>mref</code> (one of the outputs of <code>pgdsgui</code>) holds this method:</p><pre><code class="language-julia hljs">julia&gt; mref[]
spelltype(::Type{T}) where T in Main at REPL[1]:6</code></pre><p>What are the specializations, and how costly was each?</p><pre><code class="language-julia hljs">julia&gt; collect_for(mref[], tinf)
586-element Vector{SnoopCompileCore.InferenceTimingNode}:
 InferenceTimingNode: 0.003486/0.020872 on InferenceFrameInfo for spelltype(::Type{T}) where T with 7 direct children
 InferenceTimingNode: 0.003281/0.003892 on InferenceFrameInfo for spelltype(::Type{AbstractArray}) with 2 direct children
 InferenceTimingNode: 0.003349/0.004023 on InferenceFrameInfo for spelltype(::Type{AbstractChannel}) with 2 direct children
 InferenceTimingNode: 0.000827/0.001154 on InferenceFrameInfo for spelltype(::Type{AbstractChar}) with 5 direct children
 InferenceTimingNode: 0.003326/0.004070 on InferenceFrameInfo for spelltype(::Type{AbstractDict}) with 2 direct children
 InferenceTimingNode: 0.000833/0.001159 on InferenceFrameInfo for spelltype(::Type{AbstractDisplay}) with 5 direct children
⋮
 InferenceTimingNode: 0.000848/0.001160 on InferenceFrameInfo for spelltype(::Type{YAML.Span}) with 5 direct children
 InferenceTimingNode: 0.000838/0.001148 on InferenceFrameInfo for spelltype(::Type{YAML.Token}) with 5 direct children
 InferenceTimingNode: 0.000833/0.001150 on InferenceFrameInfo for spelltype(::Type{YAML.TokenStream}) with 5 direct children
 InferenceTimingNode: 0.000809/0.001126 on InferenceFrameInfo for spelltype(::Type{YAML.YAMLDocIterator}) with 5 direct children</code></pre><p>So we can see that one <code>MethodInstance</code> for each type in <code>Ts</code> was generated.</p><p>If you see a list of <code>MethodInstance</code>s, and the first is extremely costly in terms of inclusive time, but all the rest are not, then you might not need to worry much about over-specialization: your inference time will be dominated by that one costly method (often, the first time the method was called), and the fact that lots of additional specializations were generated may not be anything to worry about. However, in this case, the distribution of time is fairly flat, each contributing a small portion to the overall time. In such cases, over-specialization may be a problem.</p><h3 id="Reducing-specialization-with-@nospecialize"><a class="docs-heading-anchor" href="#Reducing-specialization-with-@nospecialize">Reducing specialization with <code>@nospecialize</code></a><a id="Reducing-specialization-with-@nospecialize-1"></a><a class="docs-heading-anchor-permalink" href="#Reducing-specialization-with-@nospecialize" title="Permalink"></a></h3><p>How might we change this? To reduce the number of specializations of <code>spelltype</code>, we use <code>@nospecialize</code> in its definition:</p><pre><code class="language-julia hljs">function spelltype(@nospecialize(T::Type))
    name = Base.unwrap_unionall(T).name.name
    str = &quot;&quot;
    for c in string(name)
        str *= c
    end
    return str
end</code></pre><div class="admonition is-warning"><header class="admonition-header">Warning</header><div class="admonition-body"><p><code>where</code> type-parameters force specialization: in <code>spelltype(@nospecialize(::Type{T})) where T</code>, the <code>@nospecialize</code> has no impact and you&#39;ll get full specialization on <code>T</code>. Instead, use <code>@nospecialize(T::Type)</code> (without the <code>where</code> statement) as shown.</p></div></div><p>If we now rerun that demo, you should see a plot of the same kind as shown above, but with different costs for each dot. The differences are best appreciated comparing them side-by-side (<a href="../../reference/#SnoopCompile.pgdsgui"><code>pgdsgui</code></a> allows you to specify a particular axis into which to plot):</p><p><img src="../../assets/pgds_compareplots.png" alt="pgdsgui-compare"/></p><p>The results with <code>@nospecialize</code> are shown on the right. You can see that:</p><ul><li>Now, the most expensive-to-infer method is &lt;0.01s (formerly it was ~1s)</li><li>No method has more than 2 specializations</li></ul><p>Moreover, our runtimes (post-compilation) really aren&#39;t very different, both in the ballpark of a few millseconds (you can check with <code>@btime</code> from BenchmarkTools to be sure).</p><p>In total, we&#39;ve reduced compilation time approximately 50× without appreciably hurting runtime performance. Reducing specialization, when appropriate, can often yield your biggest reductions in latency.</p><div class="admonition is-success"><header class="admonition-header">Tip</header><div class="admonition-body"><p>When you add <code>@nospecialize</code>, sometimes it&#39;s beneficial to compensate for the loss of inferrability by adding some type assertions. This topic will be discussed in greater detail in the next section, but for the example above we can improve runtime performance by annotating the return type of <code>Base.unwrap_unionall(T)</code>: <code>name = (Base.unwrap_unionall(T)::DataType).name.name</code>. Then, later lines in <code>spelltype</code> know that <code>name</code> is a <code>Symbol</code>.</p><p>With this change, the unspecialized variant outperforms the specialized variant in <em>both compile-time and run-time</em>. The reason is that the specialized variant of <code>spell</code> needs to be called by runtime dispatch, whereas for the unspecialized variant there&#39;s only one <code>MethodInstance</code>, so its dispatch is handled at compile time.</p></div></div><h3 id="Blocking-inference:-Base.@nospecializeinfer"><a class="docs-heading-anchor" href="#Blocking-inference:-Base.@nospecializeinfer">Blocking inference: <code>Base.@nospecializeinfer</code></a><a id="Blocking-inference:-Base.@nospecializeinfer-1"></a><a class="docs-heading-anchor-permalink" href="#Blocking-inference:-Base.@nospecializeinfer" title="Permalink"></a></h3><p>Perhaps surprisingly, <code>@nospecialize</code> doesn&#39;t prevent Julia&#39;s type-inference from inspecting a method. The reason is that it&#39;s sometimes useful if the <em>caller</em> knows what type will be returned, even if the <em>callee</em> doesn&#39;t exploit this information. In our <code>mappushes</code> example, this isn&#39;t an issue, because <code>Ts</code> is a <code>Vector{Any}</code> and this already defeats inference. But in other cases, the caller may be inferable but (to save inference time) you&#39;d prefer to block inference from inspecting the method.</p><p>Beginning with Julia 1.10, you can prevent even inference from &quot;looking at&quot; <code>@nospecialize</code>d arguments with <code>Base.@nospecializeinfer</code>:</p><pre><code class="nohighlight hljs">Base.@nospecializeinfer function spelltype(@nospecialize(T::Type))
    name = (Base.unwrap_unionall(T)::DataType).name.name
    str = &quot;&quot;
    for c in string(name)
        str *= c
    end
    return str
end</code></pre><p>Note that the <code>::DataType</code> annotation described in the tip above is still effective and recommended. <code>@nospecializeinfer</code> directly affects only arguments that are marked with <code>@nospecialize</code>, and in this case the type-assertion prevents type uncertainty from propagating to the remainder of the function.</p><h3 id="Argument-standardization"><a class="docs-heading-anchor" href="#Argument-standardization">Argument standardization</a><a id="Argument-standardization-1"></a><a class="docs-heading-anchor-permalink" href="#Argument-standardization" title="Permalink"></a></h3><p>While not immediately relevant to the example above, a very important technique that falls within the domain of reducing specialization is <em>argument standardization</em>: instead of</p><pre><code class="language-julia hljs">function foo(x, y)
    # some huge function, slow to compile, and you&#39;d prefer not to compile it many times for different types of x and y
end</code></pre><p>consider whether you can safely write this as</p><pre><code class="language-julia hljs">function foo(x::X, y::Y)   # X and Y are concrete types
    # some huge function, but the concrete typing ensures you only compile it once
end
foo(x, y) = foo(convert(X, x)::X, convert(Y, y)::Y)   # this allows you to still call it with any argument types</code></pre><p>The &quot;standardizing method&quot; <code>foo(x, y)</code> is short and therefore quick to compile, so it doesn&#39;t really matter if you compile many different instances.</p><div class="admonition is-success"><header class="admonition-header">Tip</header><div class="admonition-body"><p>In <code>convert(X, x)::X</code>, the final <code>::X</code> guards against a broken <code>convert</code> method that fails to return an object of type <code>X</code>. Without it, <code>foo(x, y)</code> might call itself in an infinite loop, ultimately triggering a StackOverflowError. StackOverflowErrors are a particularly nasty form of error, and the typeassert ensures that you get a simple <code>TypeError</code> instead.</p><p>In other contexts, such typeasserts would also have the effect of fixing inference problems even if the type of <code>x</code> is not well-inferred, but in this case dispatch to <code>foo(x::X, y::Y)</code> would have ensured the same outcome.</p></div></div><p>There are of course cases where you can&#39;t implement your code in this way: after all, part of the power of Julia is the ability of generic methods to &quot;do the right thing&quot; for a wide variety of types. But in cases where you&#39;re doing a standard task, e.g., writing some data to a file, there&#39;s really no good reason to recompile your <code>save</code> method for a filename encoded as a <code>String</code> and again for a <code>SubString{String}</code> and again for a <code>SubstitutionString</code> and again for an <code>AbstractString</code> and ...: after all, the core of the <code>save</code> method probably isn&#39;t sensitive to the precise encoding of the filename.  In such cases, it should be safe to convert all filenames to <code>String</code>, thereby reducing the diversity of input arguments for expensive-to-compile methods.</p><p>If you&#39;re using <code>pgdsgui</code>, the cost of inference and the number of specializations may guide you to click on specific dots; <code>collect_for(mref[], tinf)</code> then allows you to detect and diagnose cases where argument standardization might be helpful.</p><p>You can do the same analysis without <code>pgdsgui</code>. The opportunity for argument standardization is often facilitated by looking at, e.g.,</p><pre><code class="language-julia hljs">julia&gt; tms = accumulate_by_source(flatten(tinf));  # collect all MethodInstances that belong to the same Method

julia&gt; t, m = tms[end-1]        # the ones towards the end take the most time, maybe they are over-specialized?
(0.4138147, save(filename::AbstractString, data) in SomePkg at /pathto/SomePkg/src/SomePkg.jl:23)

julia&gt; methodinstances(m)       # let&#39;s see what specializations we have
7-element Vector{Core.MethodInstance}:
 MethodInstance for save(::String, ::Vector{SomePkg.SomeDataType})
 MethodInstance for save(::SubString{String}, ::Vector{SomePkg.SomeDataType})
 MethodInstance for save(::AbstractString, ::Vector{SomePkg.SomeDataType})
 MethodInstance for save(::String, ::Vector{SomePkg.SomeDataType{SubString{String}}})
 MethodInstance for save(::SubString{String}, ::Array)
 MethodInstance for save(::String, ::Vector{var&quot;#s92&quot;} where var&quot;#s92&quot;&lt;:SomePkg.SomeDataType)
 MethodInstance for save(::String, ::Array)</code></pre><p>In this case we have 7 <code>MethodInstance</code>s (some of which are clearly due to poor inferrability of the caller) when one might suffice.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../snoop_llvm/">« Tutorial on <code>@snoop_llvm</code></a><a class="docs-footer-nextpage" href="../jet/">Tutorial on JET integration »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.9.0 on <span class="colophon-date" title="Wednesday 26 March 2025 09:37">Wednesday 26 March 2025</span>. Using Julia version 1.11.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
