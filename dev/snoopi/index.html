<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Snooping on inference: @snoopi · SnoopCompile</title><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">SnoopCompile</a></span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">SnoopCompile.jl</a></li><li><a class="tocitem" href="../snoop_pc/">SnoopPrecompile</a></li><li><a class="tocitem" href="../tutorial/">Tutorial on the foundations</a></li><li><span class="tocitem">Modern tools</span><ul><li><a class="tocitem" href="../snoopr/">Snooping on and fixing invalidations: <code>@snoopr</code></a></li><li><a class="tocitem" href="../snoopi_deep/">Snooping on inference: <code>@snoopi_deep</code></a></li><li><a class="tocitem" href="../pgdsgui/">Profile-guided despecialization</a></li><li><a class="tocitem" href="../snoopi_deep_analysis/">Using <code>@snoopi_deep</code> results to improve inferrability</a></li><li><a class="tocitem" href="../snoopi_deep_parcel/">Using <code>@snoopi_deep</code> results for precompilation</a></li><li><a class="tocitem" href="../jet/">JET integration</a></li></ul></li><li><span class="tocitem">Older tools</span><ul><li class="is-active"><a class="tocitem" href>Snooping on inference: <code>@snoopi</code></a><ul class="internal"><li><a class="tocitem" href="#pcscripts"><span>Precompile scripts</span></a></li><li><a class="tocitem" href="#auto"><span>Producing precompile directives automatically</span></a></li><li><a class="tocitem" href="#Producing-precompile-directives-manually"><span>Producing precompile directives manually</span></a></li><li><a class="tocitem" href="#Analyzing-omitted-methods"><span>Analyzing omitted methods</span></a></li><li><a class="tocitem" href="#Understanding-precompilation-and-its-limitations"><span>Understanding precompilation and its limitations</span></a></li></ul></li><li><a class="tocitem" href="../snoopc/">Snooping on code generation: <code>@snoopc</code></a></li></ul></li><li><a class="tocitem" href="../userimg/">Creating <code>userimg.jl</code> files</a></li><li><a class="tocitem" href="../reference/">Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Older tools</a></li><li class="is-active"><a href>Snooping on inference: <code>@snoopi</code></a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Snooping on inference: <code>@snoopi</code></a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/timholy/SnoopCompile.jl/blob/master/docs/src/snoopi.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="macro-snoopi"><a class="docs-heading-anchor" href="#macro-snoopi">Snooping on inference: <code>@snoopi</code></a><a id="macro-snoopi-1"></a><a class="docs-heading-anchor-permalink" href="#macro-snoopi" title="Permalink"></a></h1><p>If you can&#39;t use <code>@snoopi_deep</code> due to Julia version constraints, the most useful choice is <code>@snoopi</code>, which is available on Julia 1.2 or higher.</p><p>Julia can cache inference results, so you can use <code>@snoopi</code> to generate <code>precompile</code> directives for your package. Executing these directives when the package is compiled may reduce compilation (inference) time when the package is used.</p><p>Here&#39;s a quick demo:</p><pre><code class="language-julia hljs">using SnoopCompile

a = rand(Float16, 5)

julia&gt; inf_timing = @snoopi sum(a)
1-element Array{Tuple{Float64,Core.MethodInstance},1}:
 (0.011293888092041016, MethodInstance for sum(::Array{Float16,1}))</code></pre><p>We defined the argument <code>a</code>, and then called <code>sum(a)</code> while &quot;snooping&quot; on inference. (The <code>i</code> in <code>@snoopi</code> means &quot;inference.&quot;) The return is a list of &quot;top level&quot; methods that got compiled, together with the amount of time spent on inference. In this case it was just a single method, which required approximately 11ms of inference time. (Inferring <code>sum</code> required inferring all the methods that it calls, but these are subsumed into the top level inference of <code>sum</code> itself.) Note that the method that got called,</p><pre><code class="language-julia hljs">julia&gt; @which sum(a)
sum(a::AbstractArray) in Base at reducedim.jl:652</code></pre><p>is much more general (i.e., defined for <code>AbstractArray</code>) than the <code>MethodInstance</code> (defined for <code>Array{Float16,1}</code>). This is because precompilation requires the types of the arguments to specialize the code appropriately.</p><p>The information obtained from <code>@snoopi</code> can be used in several ways, primarily to reduce latency during usage of your package:</p><ul><li>to help you understand which calls take the most inference time</li><li>to help you write <code>precompile</code> directives that run inference on specific calls during package precompilation, so that you don&#39;t pay this cost repeatedly each time you use the package</li><li>to help you identify inference problems that prevent successful or comprehensive precompilation</li></ul><p>If you&#39;re starting a project to try to reduce latency in your package, broadly speaking there are two paths you can take:</p><ol><li>you can use SnoopCompile, perhaps together with <a href="https://github.com/aminya/CompileBot.jl">CompileBot</a>, to automatically generate lists of precompile directives that may reduce latency;</li><li>you can use SnoopCompile primarily as an analysis tool, and then intervene manually to reduce latency.</li></ol><p>Beginners often leap at option 1, but experience shows there are good reasons to consider option 2. To avoid introducing too much complexity early on, we&#39;ll defer this discussion to the end of this page, but readers who are serious about reducing latency should be sure to read <a href="#Understanding-precompilation-and-its-limitations">Understanding precompilation and its limitations</a>.</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>Because invalidations can prevent effective precompilation, developers analyzing their packages with <code>@snoopi</code> are encouraged to use Julia versions (1.6 and higher) that have a lower risk of invalidations in Base and the standard library.</p></div></div><h2 id="pcscripts"><a class="docs-heading-anchor" href="#pcscripts">Precompile scripts</a><a id="pcscripts-1"></a><a class="docs-heading-anchor-permalink" href="#pcscripts" title="Permalink"></a></h2><p>You can use <code>@snoopi</code> to come up with a list of precompile-worthy functions. A recommended approach is to write a script that &quot;exercises&quot; the functionality you&#39;d like to precompile. One option is to use your package&#39;s <code>&quot;runtests.jl&quot;</code> file, or you can write a custom script for this purpose. Here&#39;s an example for the <a href="https://github.com/JuliaMath/FixedPointNumbers.jl">FixedPointNumbers package</a>:</p><pre><code class="nohighlight hljs">using FixedPointNumbers

x = N0f8(0.2)
y = x + x
y = x - x
y = x*x
y = x/x
y = Float32(x)
y = Float64(x)
y = 0.3*x
y = x*0.3
y = 2*x
y = x*2
y = x/15
y = x/8.0</code></pre><p>Save this as a file <code>&quot;snoopfpn.jl&quot;</code> and navigate at the Julia REPL to that directory, and then do</p><pre><code class="language-julia hljs">julia&gt; using SnoopCompile

julia&gt; inf_timing = @snoopi tmin=0.01 include(&quot;snoopfpn.jl&quot;)
2-element Array{Tuple{Float64,Core.MethodInstance},1}:
 (0.03108978271484375, MethodInstance for *(::Normed{UInt8,8}, ::Normed{UInt8,8}))
 (0.04189491271972656, MethodInstance for Normed{UInt8,8}(::Float64))</code></pre><p>Here, note the <code>tmin=0.01</code>, which causes any methods that take less than 10ms of inference time to be discarded.</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>If you&#39;re testing this, you might get different results depending on the speed of your machine. Moreover, if FixedPointNumbers has already precompiled these method and type combinations–-perhaps by incorporating a precompile file produced by SnoopCompile–-then those methods will be absent.  For packages whose precompile directives are executed only when <code>ccall(:jl_generating_output, Cint, ()) == 1</code>, you can start Julia with <code>--compiled-modules=no</code> to disable them.  Alternatively, you can <code>dev</code> the package and comment them out.</p></div></div><p>You can inspect these results and write your own precompile file, or use the automated tools provided by SnoopCompile.</p><h2 id="auto"><a class="docs-heading-anchor" href="#auto">Producing precompile directives automatically</a><a id="auto-1"></a><a class="docs-heading-anchor-permalink" href="#auto" title="Permalink"></a></h2><p>You can take the output of <code>@snoopi</code> and &quot;parcel&quot; it into packages:</p><pre><code class="language-julia hljs">julia&gt; pc = SnoopCompile.parcel(inf_timing)
Dict{Symbol,Array{String,1}} with 1 entry:
  :FixedPointNumbers =&gt; [&quot;precompile(Tuple{typeof(*),Normed{UInt8,8},Normed{UInt8,8}})&quot;, &quot;precompile(Tuple{Type{Normed{UInt8,8}},Float64})&quot;]</code></pre><p>This splits the calls up into a dictionary, <code>pc</code>, indexed by the package which &quot;owns&quot; each call. (In this case there is only one, <code>FixedPointNumbers</code>, but in more complex cases there may be several.) You can then write the results to files:</p><pre><code class="language-julia hljs">julia&gt; SnoopCompile.write(&quot;/tmp/precompile&quot;, pc)</code></pre><p>If you look in the <code>/tmp/precompile</code> directory, you&#39;ll see one or more files, named by their parent package, that may be suitable for <code>include</code>ing into the package. In this case:</p><pre><code class="nohighlight hljs">/tmp/precompile$ cat precompile_FixedPointNumbers.jl
function _precompile_()
    ccall(:jl_generating_output, Cint, ()) == 1 || return nothing
    precompile(Tuple{typeof(*),Normed{UInt8,8},Normed{UInt8,8}})
    precompile(Tuple{Type{Normed{UInt8,8}},Float64})
end</code></pre><p>If you copy this file to a <code>precompile.jl</code> file in the <code>src</code> directory, you can incorporate it into the package like this:</p><pre><code class="language-julia hljs">module FixedPointNumbers

# All the usual commands that define the module go here

# ... followed by:

include(&quot;precompile.jl&quot;)
_precompile_()

end # module FixedPointNumbers</code></pre><p>The listed method/type combinations should have their inference results cached. Load the package once to precompile it, and then in a fresh Julia session try this:</p><pre><code class="language-julia hljs">julia&gt; using SnoopCompile

julia&gt; inf_timing = @snoopi tmin=0.01 include(&quot;snoopfpn.jl&quot;)
0-element Array{Tuple{Float64,Core.MethodInstance},1}</code></pre><p>The fact that no methods were returned is a sign of success: Julia didn&#39;t need to call inference on those methods, because it used the inference results from the cache file.</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>Sometimes, <code>@snoopi</code> will show method &amp; type combinations that you precompiled. This is a sign that despite your attempts, Julia declined to cache the inference results for those methods. You can either delete those directives from the precompile file, or hope that they will become useful in a future version of Julia. Note that having many &quot;useless&quot; precompile directives can slow down precompilation.</p></div></div><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>As you develop your package, it&#39;s possible you&#39;ll modify or delete some of the methods that appear in your <code>&quot;precompile.jl&quot;</code> file. This will <em>not</em> result in an error; by default <code>precompile</code> fails silently. If you want to be certain that your precompile directives don&#39;t go stale, you can check that <code>precompile</code> returns <code>true</code> and otherwise issue a warning. By default, <a href="../reference/#SnoopCompile.write"><code>SnoopCompile.write</code></a> generates a macro, <code>@warnpcfail</code>, and you can use it by changing <code>precompile(args...)</code> to <code>@warnpcfail precompile(args...)</code>.</p></div></div><p>If you find that some precompile directives are ineffective (they appear in a new <code>@snoopi</code> despite being precompiled) and their inference time is substantial, sometimes a bit of manual investigation of the callees can lead to insights. For example, you might be able to introduce a precompile in a dependent package that can mitigate the total time. (<code>@snoopi_deep</code> makes the analysis and resolution of these issues more straightforward.)</p><div class="admonition is-success"><header class="admonition-header">Tip</header><div class="admonition-body"><p>For packages that support just Julia 1.6 and higher, you may be able to slim down the precompile file by adding <code>has_bodyfunction=true</code> to the arguments for <code>parcel</code>. This setting applies for all packges in <code>inf_timing</code>, so you may need to call <code>parcel</code> twice (with both <code>false</code> and <code>true</code>) and select the appropriate precompile file for each package.</p></div></div><h2 id="Producing-precompile-directives-manually"><a class="docs-heading-anchor" href="#Producing-precompile-directives-manually">Producing precompile directives manually</a><a id="Producing-precompile-directives-manually-1"></a><a class="docs-heading-anchor-permalink" href="#Producing-precompile-directives-manually" title="Permalink"></a></h2><p>While this &quot;automated&quot; approach is often useful, sometimes it makes more sense to inspect the results and write your own precompile directives. For example, for FixedPointNumbers a more elegant and comprehensive precompile file might be</p><pre><code class="language-julia hljs">function _precompile_()
    ccall(:jl_generating_output, Cint, ()) == 1 || return nothing
    for T in (N0f8, N0f16)      # Normed types we want to support
        for f in (+, -, *, /)   # operations we want to support
            precompile(Tuple{typeof(f),T,T})
            for S in (Float32, Float64, Int)   # other number types we want to support
                precompile(Tuple{typeof(f),T,S})
                precompile(Tuple{typeof(f),S,T})
            end
        end
        for S in (Float32, Float64)
            precompile(Tuple{Type{T},S})
            precompile(Tuple{Type{S},T})
        end
    end
end</code></pre><p>This covers <code>+</code>, <code>-</code>, <code>*</code>, <code>/</code>, and conversion for various combinations of types. The results from <code>@snoopi</code> can suggest method/type combinations that might be useful to precompile, but often you can generalize its suggestions in useful ways.</p><h2 id="Analyzing-omitted-methods"><a class="docs-heading-anchor" href="#Analyzing-omitted-methods">Analyzing omitted methods</a><a id="Analyzing-omitted-methods-1"></a><a class="docs-heading-anchor-permalink" href="#Analyzing-omitted-methods" title="Permalink"></a></h2><p>There are some method signatures that cannot be precompiled. For example, suppose you have two packages, <code>A</code> and <code>B</code>, that are independent of one another. Then <code>A.f([B.Object(1)])</code> cannot be precompiled, because <code>A</code> does not know about <code>B.Object</code>, and <code>B</code> does not know about <code>A.f</code>, unless both <code>A</code> and <code>B</code> get included into a third package.</p><p>Such problematic method signatures are removed automatically. If you want to be informed about these removals, you can use Julia&#39;s logging framework while running <code>parcel</code>:</p><pre><code class="nohighlight hljs">julia&gt; using Base.CoreLogging

julia&gt; logger = SimpleLogger(IOBuffer(), CoreLogging.Debug);

julia&gt; pc = with_logger(logger) do
           SnoopCompile.parcel(inf_timing)
       end

julia&gt; msgs = String(take!(logger.stream))</code></pre><p>The omitted method signatures will be logged to the string <code>msgs</code>.</p><h2 id="Understanding-precompilation-and-its-limitations"><a class="docs-heading-anchor" href="#Understanding-precompilation-and-its-limitations">Understanding precompilation and its limitations</a><a id="Understanding-precompilation-and-its-limitations-1"></a><a class="docs-heading-anchor-permalink" href="#Understanding-precompilation-and-its-limitations" title="Permalink"></a></h2><p>Suppose your package includes the following method:</p><pre><code class="language-julia hljs">&quot;&quot;&quot;
    idx = index_midsum(a)

Return the index of the first item more than &quot;halfway to the cumulative sum,&quot;
meaning the smallest integer so that `sum(a[begin:idx]) &gt;= sum(a)/2`.
&quot;&quot;&quot;
function index_midsum(a::AbstractVector)
    ca = cumsum(vcat(0, a))   # cumulative sum of items in a, starting from 0
    s = ca[end]               # the sum of all elements
    return findfirst(x-&gt;x &gt;= s/2, ca) - 1  # compensate for inserting 0
end</code></pre><p>Now, suppose that you&#39;d like to reduce latency in using this method, and you know that an important use case is when <code>a</code> is a <code>Vector{Int}</code>. Therefore, you might precompile it:</p><pre><code class="language-julia hljs">julia&gt; precompile(index_midsum, (Vector{Int},))
true</code></pre><p>This will cause Julia to infer this method for the given argument types. If you add such statements to your package, it potentially saves your users from having to wait for it to be inferred each time they use your package.</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>The <code>true</code> indicates that Julia was successfully able to find a method supporting this signature and precompile it. See the note about <code>@warnpcfail</code> above for ways to exploit this in your package.</p></div></div><p>But if you execute these lines in the REPL, and then check how well it worked, you might see something like the following:</p><pre><code class="language-julia hljs">julia&gt; using SnoopCompile

julia&gt; tinf = @snoopi index_midsum([1,2,3,4,100])
3-element Vector{Tuple{Float64, Core.MethodInstance}}:
 (0.00048613548278808594, MethodInstance for cat_similar(::Int64, ::Type, ::Tuple{Int64}))
 (0.010090827941894531, MethodInstance for (::Base.var&quot;#cat_t##kw&quot;)(::NamedTuple{(:dims,), Tuple{Val{1}}}, ::typeof(Base.cat_t), ::Type{Int64}, ::Int64, ::Vararg{Any, N} where N))
 (0.016659975051879883, MethodInstance for __cat(::Vector{Int64}, ::Tuple{Int64}, ::Tuple{Bool}, ::Int64, ::Vararg{Any, N} where N))</code></pre><p>Even though we&#39;d already said <code>precompile(index_midsum, (Vector{Int},))</code> in this session, somehow we needed <em>more</em> inference of various concatenation methods. Why does this happen? A detailed investigation (e.g., using <a href="https://github.com/JuliaDebug/Cthulhu.jl">Cthulhu</a> or <code>@code_warntype</code>) would reveal that <code>vcat(0, a)</code> is not inferrable &quot;all the way down,&quot; and hence the <code>precompile</code> directive couldn&#39;t predict everything that was going to be needed.</p><p>No problem, you say: let&#39;s just precompile those methods too. The most expensive is the last one. You might not know where <code>__cat</code> is defined, but you can find out with</p><pre><code class="language-julia hljs">julia&gt; mi = tinf[end][2]    # get the MethodInstance
MethodInstance for __cat(::Vector{Int64}, ::Tuple{Int64}, ::Tuple{Bool}, ::Int64, ::Vararg{Any, N} where N)

julia&gt; mi.def               # get the Method
__cat(A, shape::Tuple{Vararg{Int64, M}}, catdims, X...) where M in Base at abstractarray.jl:1599

julia&gt; mi.def.module        # which module was this method defined in?
Base</code></pre><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>When using <code>@snoopi</code> you might sometimes see entries like <code>MethodInstance for (::SomeModule.var&quot;#10#12&quot;{SomeType})(::AnotherModule.AnotherType)</code>. These typically correspond to closures/anonymous functions defined with <code>-&gt;</code> or <code>do</code> blocks, but it may not be immediately obvious where these come from. <code>mi.def</code> will show you the file/line number that these are defined on. You can either convert them into named functions to make them easier to precompile, or you can fix inference problems that prevent automatic precompilation (as illustrated below).</p></div></div><p>Armed with this knowledge, let&#39;s start a fresh session (so that nothing is precompiled yet), and in addition to defining <code>index_midsum</code> and precompiling it, we also execute</p><pre><code class="language-julia hljs">julia&gt; precompile(Base.__cat, (Vector{Int64}, Tuple{Int64}, Tuple{Bool}, Int, Vararg{Any, N} where N))
true</code></pre><p>Now if you try that <code>tinf = @snoopi index_midsum([1,2,3,4,100])</code> line, you&#39;ll see that the <code>__cat</code> call is omitted, suggesting success.</p><p>However, if you copy both <code>precompile</code> directives into your package source files and then check it with <code>@snoopi</code> again, you may be in for a rude surprise: the <code>__cat</code> precompile directive doesn&#39;t &quot;work.&quot; That turns out to be because your package doesn&#39;t &quot;own&quot; that <code>__cat</code> method–the module is <code>Base</code> rather than <code>YourPackage</code>–and because inference cannot determine that it&#39;s needed by by <code>index_midsum(::Vector{Int})</code>, Julia doesn&#39;t know which <code>*.ji</code> file to use to store its precompiled form.</p><p>How to fix this? Fundamentally, the problem is that <code>vcat</code> call: if we can write <code>index_midsum</code> in a way so that inference succeeds, then all these problems go away. (You can use <code>ascend(mi)</code>, where <code>mi</code> was obtained above, to discover that <code>__cat</code> gets called from <code>vcat</code>. See <a href="../snoopr/#ascend">ascend</a> for more information.) It turns out that <code>vcat</code> is inferrable if all the arguments have the same type, so just changing <code>vcat(0, a)</code> to <code>vcat([zero(eltype(a))], a)</code> fixes the problem. (Alternatively, you could make a copy and then use <code>pushfirst!</code>.) In a fresh Julia session:</p><pre><code class="language-julia hljs">function index_midsum(a::AbstractVector)
    ca = cumsum(vcat([zero(eltype(a))], a))   # cumulative sum of items in a, starting from 0
    s = ca[end]               # the sum of all elements
    return findfirst(x-&gt;x &gt;= s/2, ca) - 1  # compensate for inserting 0
end

julia&gt; precompile(index_midsum, (Vector{Int},))
true

julia&gt; using SnoopCompile

julia&gt; tinf = @snoopi index_midsum([1,2,3,4,100])
Tuple{Float64, Core.MethodInstance}[]</code></pre><p>Tada! No additional inference was needed, ensuring that your users will not suffer any latency due to type-inference of this particular method/argument combination. In addition to identifing a call deserving of precompilation, <code>@snoopi</code> helped us identify a weakness in its implementation. Fixing that weakness reduced latency, made the code more resistant to invalidation, and may improve runtime performance.</p><p>In other cases, manual inspection of the results from <code>@snoopi</code> may lead you in a different direction: you may discover that a huge number of specializations are being created for a method that doesn&#39;t need them. Typical examples are methods that take types or functions as inputs: for example, there is no reason to recompile <code>methods(f)</code> for each separate <code>f</code>. In such cases, by far your best option is to add <code>@nospecialize</code> annotations to one or more of the arguments of that method. Such changes can have dramatic impact on the latency of your package.</p><p>The ability to make interventions like these–which can both reduce latency and improve runtime speed–is a major reason to consider <code>@snoopi</code> primarily as an analysis tool rather than just a utility to blindly generate lists of precompile directives.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../jet/">« JET integration</a><a class="docs-footer-nextpage" href="../snoopc/">Snooping on code generation: <code>@snoopc</code> »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.24 on <span class="colophon-date" title="Monday 5 June 2023 14:41">Monday 5 June 2023</span>. Using Julia version 1.9.0.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
